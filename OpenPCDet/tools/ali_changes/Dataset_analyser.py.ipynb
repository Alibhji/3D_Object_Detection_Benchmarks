{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-21 01:21:41,183   INFO  **********************Start logging**********************\n",
      "2020-08-21 01:21:41,185   INFO  CUDA_VISIBLE_DEVICES=ALL\n",
      "2020-08-21 01:21:41,185   INFO  cfg_file         ./my_pointrcnn.yaml\n",
      "2020-08-21 01:21:41,186   INFO  batch_size       1\n",
      "2020-08-21 01:21:41,187   INFO  epochs           80\n",
      "2020-08-21 01:21:41,187   INFO  workers          1\n",
      "2020-08-21 01:21:41,188   INFO  extra_tag        default\n",
      "2020-08-21 01:21:41,188   INFO  ckpt             None\n",
      "2020-08-21 01:21:41,189   INFO  pretrained_model None\n",
      "2020-08-21 01:21:41,189   INFO  launcher         none\n",
      "2020-08-21 01:21:41,190   INFO  tcp_port         18888\n",
      "2020-08-21 01:21:41,190   INFO  sync_bn          False\n",
      "2020-08-21 01:21:41,191   INFO  fix_random_seed  False\n",
      "2020-08-21 01:21:41,191   INFO  ckpt_save_interval 1\n",
      "2020-08-21 01:21:41,191   INFO  local_rank       0\n",
      "2020-08-21 01:21:41,192   INFO  max_ckpt_save_num 30\n",
      "2020-08-21 01:21:41,192   INFO  merge_all_iters_to_one_epoch False\n",
      "2020-08-21 01:21:41,193   INFO  set_cfgs         None\n",
      "2020-08-21 01:21:41,193   INFO  max_waiting_mins 0\n",
      "2020-08-21 01:21:41,194   INFO  start_epoch      0\n",
      "2020-08-21 01:21:41,194   INFO  save_to_file     False\n",
      "2020-08-21 01:21:41,195   INFO  cfg.ROOT_DIR: /home/mjamali/proj/G_All_b/3D_Object_Detection_Benchmarks/OpenPCDet\n",
      "2020-08-21 01:21:41,195   INFO  cfg.LOCAL_RANK: 0\n",
      "2020-08-21 01:21:41,196   INFO  cfg.CLASS_NAMES: ['Car', 'Pedestrian', 'Cyclist']\n",
      "2020-08-21 01:21:41,196   INFO  \n",
      "cfg.DATA_CONFIG = edict()\n",
      "2020-08-21 01:21:41,197   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset\n",
      "2020-08-21 01:21:41,201   INFO  cfg.DATA_CONFIG.DATA_PATH: ../../data/kitti\n",
      "2020-08-21 01:21:41,202   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 70.4, 40, 1]\n",
      "2020-08-21 01:21:41,202   INFO  \n",
      "cfg.DATA_CONFIG.DATA_SPLIT = edict()\n",
      "2020-08-21 01:21:41,203   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train\n",
      "2020-08-21 01:21:41,204   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val\n",
      "2020-08-21 01:21:41,204   INFO  \n",
      "cfg.DATA_CONFIG.INFO_PATH = edict()\n",
      "2020-08-21 01:21:41,205   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']\n",
      "2020-08-21 01:21:41,205   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']\n",
      "2020-08-21 01:21:41,206   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True\n",
      "2020-08-21 01:21:41,206   INFO  \n",
      "cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()\n",
      "2020-08-21 01:21:41,208   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']\n",
      "2020-08-21 01:21:41,208   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:20', 'Pedestrian:15', 'Cyclist:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]\n",
      "2020-08-21 01:21:41,209   INFO  \n",
      "cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()\n",
      "2020-08-21 01:21:41,209   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding\n",
      "2020-08-21 01:21:41,210   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2020-08-21 01:21:41,211   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']\n",
      "2020-08-21 01:21:41,212   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'sample_points', 'NUM_POINTS': {'train': 16384, 'test': 16384}}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}]\n",
      "2020-08-21 01:21:41,212   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: ./my_kitti_dataset.yaml\n",
      "2020-08-21 01:21:41,213   INFO  \n",
      "cfg.MODEL = edict()\n",
      "2020-08-21 01:21:41,213   INFO  cfg.MODEL.NAME: MyModel\n",
      "2020-08-21 01:21:41,214   INFO  \n",
      "cfg.MODEL.BACKBONE_3D = edict()\n",
      "2020-08-21 01:21:41,215   INFO  cfg.MODEL.BACKBONE_3D.NAME: PointNet2MSG\n",
      "2020-08-21 01:21:41,216   INFO  \n",
      "cfg.MODEL.BACKBONE_3D.SA_CONFIG = edict()\n",
      "2020-08-21 01:21:41,216   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NPOINTS: [4096, 1024, 256, 64]\n",
      "2020-08-21 01:21:41,216   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.RADIUS: [[0.1, 0.5], [0.5, 1.0], [1.0, 2.0], [2.0, 4.0]]\n",
      "2020-08-21 01:21:41,217   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.NSAMPLE: [[16, 32], [16, 32], [16, 32], [16, 32]]\n",
      "2020-08-21 01:21:41,218   INFO  cfg.MODEL.BACKBONE_3D.SA_CONFIG.MLPS: [[[16, 16, 32], [32, 32, 64]], [[64, 64, 128], [64, 96, 128]], [[128, 196, 256], [128, 196, 256]], [[256, 256, 512], [256, 384, 512]]]\n",
      "2020-08-21 01:21:41,218   INFO  cfg.MODEL.BACKBONE_3D.FP_MLPS: [[128, 128], [256, 256], [512, 512], [512, 512]]\n",
      "2020-08-21 01:21:41,219   INFO  \n",
      "cfg.MODEL.SEMANSEGMENT = edict()\n",
      "2020-08-21 01:21:41,220   INFO  cfg.MODEL.SEMANSEGMENT.NAME: SegNet\n",
      "2020-08-21 01:21:41,220   INFO  \n",
      "cfg.MODEL.SEMANSEGMENT.MODELCONFIG = edict()\n",
      "2020-08-21 01:21:41,221   INFO  cfg.MODEL.SEMANSEGMENT.MODELCONFIG.in_channels: 3\n",
      "2020-08-21 01:21:41,221   INFO  cfg.MODEL.SEMANSEGMENT.MODELCONFIG.num_features: 128\n",
      "2020-08-21 01:21:41,222   INFO  cfg.MODEL.SEMANSEGMENT.MODELCONFIG.pretrained: True\n",
      "2020-08-21 01:21:41,222   INFO  cfg.MODEL.SEMANSEGMENT.MODELCONFIG.freeze_bn: False\n",
      "2020-08-21 01:21:41,223   INFO  \n",
      "cfg.MODEL.POST_PROCESSING = edict()\n",
      "2020-08-21 01:21:41,223   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
      "2020-08-21 01:21:41,223   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1\n",
      "2020-08-21 01:21:41,224   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False\n",
      "2020-08-21 01:21:41,224   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti\n",
      "2020-08-21 01:21:41,225   INFO  \n",
      "cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()\n",
      "2020-08-21 01:21:41,225   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False\n",
      "2020-08-21 01:21:41,226   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu\n",
      "2020-08-21 01:21:41,226   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1\n",
      "2020-08-21 01:21:41,227   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096\n",
      "2020-08-21 01:21:41,227   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500\n",
      "2020-08-21 01:21:41,230   INFO  \n",
      "cfg.OPTIMIZATION = edict()\n",
      "2020-08-21 01:21:41,231   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2\n",
      "2020-08-21 01:21:41,231   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 80\n",
      "2020-08-21 01:21:41,232   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle\n",
      "2020-08-21 01:21:41,232   INFO  cfg.OPTIMIZATION.LR: 0.01\n",
      "2020-08-21 01:21:41,233   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01\n",
      "2020-08-21 01:21:41,233   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9\n",
      "2020-08-21 01:21:41,234   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]\n",
      "2020-08-21 01:21:41,234   INFO  cfg.OPTIMIZATION.PCT_START: 0.4\n",
      "2020-08-21 01:21:41,235   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10\n",
      "2020-08-21 01:21:41,235   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]\n",
      "2020-08-21 01:21:41,236   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1\n",
      "2020-08-21 01:21:41,236   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07\n",
      "2020-08-21 01:21:41,237   INFO  cfg.OPTIMIZATION.LR_WARMUP: False\n",
      "2020-08-21 01:21:41,237   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1\n",
      "2020-08-21 01:21:41,240   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10\n",
      "2020-08-21 01:21:41,240   INFO  cfg.TAG: my_pointrcnn\n",
      "2020-08-21 01:21:41,241   INFO  cfg.EXP_GROUP_PATH: \n",
      "2020-08-21 01:21:41,683   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2020-08-21 01:21:41,685   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2020-08-21 01:21:41,686   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2020-08-21 01:21:41,713   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2020-08-21 01:21:41,717   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2020-08-21 01:21:41,719   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2020-08-21 01:21:41,727   INFO  Loading KITTI dataset\n",
      "2020-08-21 01:21:41,856   INFO  Total samples for KITTI dataset: 3712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../cfgs/kitti_models/my_pointrcnn.yaml\n",
      "./my_pointrcnn.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "import datetime\n",
    "\n",
    "from pcdet.models import build_network, model_fn_decorator\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model\n",
    "import torch\n",
    "import glob\n",
    "# from .test import repeat_eval_ckpt\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = {'cfg_file': '../cfgs/kitti_models/my_pointrcnn.yaml', 'batch_size': 1, 'epochs': None, 'workers': 1, 'extra_tag': 'default', 'ckpt': None, 'pretrained_model': None, 'launcher': 'none', 'tcp_port': 18888, 'sync_bn': False, 'fix_random_seed': False, 'ckpt_save_interval': 1, 'local_rank': 0, 'max_ckpt_save_num': 30, 'merge_all_iters_to_one_epoch': False, 'set_cfgs': None, 'max_waiting_mins': 0, 'start_epoch': 0, 'save_to_file': False}\n",
    "\n",
    "args = Struct(**args)\n",
    "print(args.cfg_file)\n",
    "\n",
    "\n",
    "args.cfg_file= \"./my_pointrcnn.yaml\"\n",
    "print(args.cfg_file)\n",
    "cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "cfg.TAG = Path(args.cfg_file).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "\n",
    "if args.launcher == 'none':\n",
    "    dist_train = False\n",
    "    total_gpus = 1\n",
    "else:\n",
    "    total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "        args.tcp_port, args.local_rank, backend='nccl'\n",
    "    )\n",
    "    dist_train = True\n",
    "\n",
    "if args.batch_size is None:\n",
    "    args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "else:\n",
    "    assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "    args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "if args.fix_random_seed:\n",
    "    common_utils.set_random_seed(666)\n",
    "\n",
    "output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / cfg.TAG / args.extra_tag\n",
    "ckpt_dir = output_dir / 'ckpt'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_file = output_dir / ('log_train_%s.txt' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "logger = common_utils.create_logger(log_file, rank=cfg.LOCAL_RANK)\n",
    "\n",
    "# log to file\n",
    "logger.info('**********************Start logging**********************')\n",
    "gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "if dist_train:\n",
    "    logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "for key, val in vars(args).items():\n",
    "    logger.info('{:16} {}'.format(key, val))\n",
    "log_config_to_file(cfg, logger=logger)\n",
    "if cfg.LOCAL_RANK == 0:\n",
    "    os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "from pcdet.datasets import build_dataloader\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        batch_size=args.batch_size,\n",
    "        dist=dist_train, workers=args.workers,\n",
    "        logger=logger,\n",
    "        training=True,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,\n",
    "        total_epochs=args.epochs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# wx, gtk, osx, tk, empty uses default\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.dataset_tools import draw_point_cloud\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "image_path = train_set.root_split_path\n",
    "frame=train_set[12]\n",
    "\n",
    "\n",
    "image2 = os.path.join(image_path ,'image_2',frame['frame_id']+'.png' )\n",
    "image2 = cv2.imread(image2)\n",
    "\n",
    "image3 = os.path.join(image_path ,'image_3',frame['frame_id']+'.png' )\n",
    "image3 = cv2.imread(image3)\n",
    "\n",
    "f, ax = plt.subplots( 2, figsize=(15, 5))\n",
    "ax[0].set_title('Left RGB Image (cam2)')\n",
    "ax[0].imshow(image2)\n",
    "ax[1].set_title('Right RGB Image (cam3)')\n",
    "ax[1].imshow(image3)\n",
    "plt.show()\n",
    "\n",
    "f2 = plt.figure(figsize=(15, 8))\n",
    "ax2 = f2.add_subplot(111, projection='3d')\n",
    "draw_point_cloud(frame,ax2, 'Velodyne scan', xlim3d=(-10,30))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'points': array([[10.76 ,  8.644, -1.495,  0.3  ],\n        [ 6.157, -1.246, -1.639,  0.34 ],\n        [13.892, 11.318, -1.237,  0.22 ],\n        ...,\n        [14.325, 11.936, -0.515,  0.11 ],\n        [11.977, -6.296,  0.344,  0.5  ],\n        [ 9.698,  6.13 , -1.56 ,  0.36 ]], dtype=float32),\n 'frame_id': '000000',\n 'calib': <pcdet.utils.calibration_kitti.Calibration at 0x7f1df2e0eeb8>,\n 'image2': array([[[0.07058824, 0.08627451, 0.06666667],\n         [0.10980392, 0.09411765, 0.0627451 ],\n         [0.12941176, 0.11372549, 0.09803922],\n         ...,\n         [0.09019608, 0.11372549, 0.14509804],\n         [0.08235294, 0.09411765, 0.1372549 ],\n         [0.05882353, 0.06666667, 0.14117647]],\n \n        [[0.0627451 , 0.0745098 , 0.06666667],\n         [0.07843137, 0.09019608, 0.05490196],\n         [0.09411765, 0.10980392, 0.09411765],\n         ...,\n         [0.09803922, 0.11372549, 0.14509804],\n         [0.08235294, 0.09803922, 0.1372549 ],\n         [0.05490196, 0.07058824, 0.1372549 ]],\n \n        [[0.0627451 , 0.0627451 , 0.06666667],\n         [0.0745098 , 0.0627451 , 0.07058824],\n         [0.08235294, 0.08235294, 0.07058824],\n         ...,\n         [0.10588235, 0.11372549, 0.13333333],\n         [0.08627451, 0.09019608, 0.1254902 ],\n         [0.05490196, 0.06666667, 0.11764706]],\n \n        ...,\n \n        [[0.10980392, 0.09019608, 0.0745098 ],\n         [0.10980392, 0.08627451, 0.06666667],\n         [0.10980392, 0.08627451, 0.0627451 ],\n         ...,\n         [0.1254902 , 0.09803922, 0.09411765],\n         [0.1254902 , 0.10196078, 0.07843137],\n         [0.12156863, 0.10588235, 0.07843137]],\n \n        [[0.10980392, 0.08235294, 0.04705882],\n         [0.09803922, 0.0745098 , 0.04705882],\n         [0.09411765, 0.07058824, 0.05490196],\n         ...,\n         [0.12941176, 0.09803922, 0.07843137],\n         [0.1254902 , 0.09803922, 0.08235294],\n         [0.11764706, 0.10588235, 0.08235294]],\n \n        [[0.09019608, 0.07843137, 0.05098039],\n         [0.07058824, 0.07058824, 0.05490196],\n         [0.0745098 , 0.06666667, 0.05490196],\n         ...,\n         [0.14509804, 0.11764706, 0.08627451],\n         [0.14901961, 0.11372549, 0.08627451],\n         [0.1372549 , 0.11764706, 0.07843137]]]),\n 'gt_boxes': array([[ 8.73138  , -1.8559176, -0.6546994,  1.2      ,  0.48     ,\n          1.89     , -1.5807964,  2.       ]], dtype=float32),\n 'road_plane': array([-0.00705174, -0.99977906, -0.0198015 ,  1.68036694]),\n 'use_lead_xyz': True,\n 'image_shape': array([ 370, 1224], dtype=int32)}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# import  numpy as np\n",
    "#\n",
    "# gt = train_set[0]['gt_boxes'][0]\n",
    "# x, y, z = gt[0:3]\n",
    "# w, l, h = gt[3:6]\n",
    "# # in velodyne coordinates around zero point and without orientation yet\n",
    "# trackletBox = np.array([\n",
    "#     [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "#     [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "#     [0.0, 0.0, 0.0, 0.0, h, h, h, h]\n",
    "# ])\n",
    "#\n",
    "# yaw = gt[6]\n",
    "# rotMat = np.array([\n",
    "#                 [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "#                 [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "#                 [0.0, 0.0, 1.0]\n",
    "#             ])\n",
    "#\n",
    "# cornerPosInVelo = np.dot(rotMat, trackletBox)+np.array([[x,y,z]]).T\n",
    "# train_set[100]\n",
    "# os.path.join(image_path ,'image2',frame['frame_id']+'.png' )\n",
    "# # translation = np.array([\n",
    "# #                 [1, 0.0, 0.0],\n",
    "# #                 [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "# #                 [0.0, 0.0, 1.0]\n",
    "# #             ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-21 01:21:46,286   INFO  MyModel(\n",
      "  (vfe): None\n",
      "  (backbone_3d): PointNet2MSG(\n",
      "    (SA_modules): ModuleList(\n",
      "      (0): PointnetSAModuleMSG(\n",
      "        (groupers): ModuleList(\n",
      "          (0): QueryAndGroup()\n",
      "          (1): QueryAndGroup()\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): PointnetSAModuleMSG(\n",
      "        (groupers): ModuleList(\n",
      "          (0): QueryAndGroup()\n",
      "          (1): QueryAndGroup()\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): PointnetSAModuleMSG(\n",
      "        (groupers): ModuleList(\n",
      "          (0): QueryAndGroup()\n",
      "          (1): QueryAndGroup()\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): PointnetSAModuleMSG(\n",
      "        (groupers): ModuleList(\n",
      "          (0): QueryAndGroup()\n",
      "          (1): QueryAndGroup()\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "            (6): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (8): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (FP_modules): ModuleList(\n",
      "      (0): PointnetFPModule(\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv2d(257, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): PointnetFPModule(\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): PointnetFPModule(\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (3): PointnetFPModule(\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sematic_segmentation): SegNet(\n",
      "    (stage1_encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage2_encoder): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage3_encoder): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage4_encoder): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage5_encoder): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (stage1_decoder): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage2_decoder): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage3_decoder): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage4_decoder): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (stage5_decoder): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "  )\n",
      "  (map_to_bev_module): None\n",
      "  (pfe): None\n",
      "  (backbone_2d): None\n",
      "  (dense_head): None\n",
      "  (point_head): None\n",
      "  (roi_head): None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    if args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    # load checkpoint if it is possible\n",
    "    start_epoch = it = 0\n",
    "    last_epoch = -1\n",
    "    if args.pretrained_model is not None:\n",
    "        model.load_params_from_file(filename=args.pretrained_model, to_cpu=dist, logger=logger)\n",
    "\n",
    "    if args.ckpt is not None:\n",
    "        it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "        last_epoch = start_epoch + 1\n",
    "    else:\n",
    "        ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "        if len(ckpt_list) > 0:\n",
    "            ckpt_list.sort(key=os.path.getmtime)\n",
    "            it, start_epoch = model.load_params_with_optimizer(\n",
    "                ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "            )\n",
    "            last_epoch = start_epoch + 1\n",
    "\n",
    "    model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "    if dist_train:\n",
    "        model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "    logger.info(model)\n",
    "\n",
    "    lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "        optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "        last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "    # logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "    #             % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "    # train_model(\n",
    "    #     model,\n",
    "    #     optimizer,\n",
    "    #     train_loader,\n",
    "    #     model_func=model_fn_decorator(),\n",
    "    #     lr_scheduler=lr_scheduler,\n",
    "    #     optim_cfg=cfg.OPTIMIZATION,\n",
    "    #     start_epoch=start_epoch,\n",
    "    #     total_epochs=args.epochs,\n",
    "    #     start_iter=it,\n",
    "    #     rank=cfg.LOCAL_RANK,\n",
    "    #     tb_log=tb_log,\n",
    "    #     ckpt_save_dir=ckpt_dir,\n",
    "    #     train_sampler=train_sampler,\n",
    "    #     lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "    #     ckpt_save_interval=args.ckpt_save_interval,\n",
    "    #     max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "    #     merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "    # )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-21 01:21:46,301   INFO  **********************End training /my_pointrcnn(default)**********************\n",
      "\n",
      "\n",
      "\n",
      "2020-08-21 01:21:46,302   INFO  **********************Start evaluation /my_pointrcnn(default)**********************\n",
      "2020-08-21 01:21:46,305   INFO  Loading KITTI dataset\n",
      "2020-08-21 01:21:46,441   INFO  Total samples for KITTI dataset: 3769\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'repeat_eval_ckpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-370679ca5a55>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_epoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Only evaluate the last 10 epochs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m repeat_eval_ckpt(\n\u001B[0m\u001B[1;32m     17\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdist_train\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_output_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mckpt_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'repeat_eval_ckpt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.info('**********************End training %s/%s(%s)**********************\\n\\n\\n'\n",
    "            % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "logger.info('**********************Start evaluation %s/%s(%s)**********************' %\n",
    "            (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=args.batch_size,\n",
    "    dist=dist_train, workers=args.workers, logger=logger, training=False\n",
    ")\n",
    "eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "\n",
    "repeat_eval_ckpt(\n",
    "    model.module if dist_train else model,\n",
    "    test_loader, args, eval_output_dir, logger, ckpt_dir,\n",
    "    dist_test=dist_train\n",
    ")\n",
    "logger.info('**********************End evaluation %s/%s(%s)**********************' %\n",
    "            (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}